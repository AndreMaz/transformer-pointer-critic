{
    "description": "Hyper params for Multiple Knapsack problem",
    
    "trainer_config": {
        "description": "Trainer function configs.",
        "n_iterations": 100,
        "n_steps_to_update": 20
    },

    "env_config": {
        "description": "Environment configs.",

        "load_from_file": false,
        "location": "./environment/custom/knapsack/problem.json",
        
        "batch_size": 32,
        "num_items": 100,
        "num_backpacks": 10,
        "EOS_CODE": 0,

        "sampling_mode": false,
        "item_sample_size": 20,
        "backpack_sample_size": 5,

        "normalization_factor": 1,

        "min_item_value": 1,
        "max_item_value": 100,
        "min_item_weight": 1,
        "max_item_weight": 20,

        "min_backpack_capacity": 10,
        "max_backpack_capacity": 20,

        "compute_mha_mask": true
    },

    "dpc": {
        "description": "Double Pointer Critic Agent configs.",
        "agent_config": {

            "gamma": 0.999,
            "entropy_coefficient": 0.00001,
            "stochastic_action_selection": true,

            "actor": {
                "SOS_CODE": -1,
                "learning_rate": 0.0001,

                "encoder_embedding_size": 128,
                "encoder_embedding_time_distributed": true,
                "encoder_lstm_units": 128,

                "attention_dense_units": 128
            },

            "critic": {
                "learning_rate": 0.0001,

                "encoder_embedding_size": 128,
                "encoder_embedding_time_distributed": true,
                "encoder_lstm_units": 128,

                "processing_lstm_units": 128,
                "processing_dense_units": 128,

                "decoder_units": 128,
                "decoder_activation": "relu"
            }
        }
    },

    "tpc": {
        "description": "Double Transformer Pointer Critic Agent configs.",
        "agent_config": {

            "gamma": 0.999,
            "entropy_coefficient": 0.00001,
            "stochastic_action_selection": true,
            "use_mha_mask": true,

            "actor": {
                "num_layers": 1,
                "dim_model": 128,
                "num_heads": 8,
                "inner_layer_dim": 128,
                "positional_encoding": false,
                "SOS_CODE": -1,
                "encoder_embedding_time_distributed": true,
                "attention_dense_units": 128,
                "dropout_rate": 0.01,

                "learning_rate": 0.0001
            },

            "critic": {
                "num_layers": 1,
                "dim_model": 128,
                "num_heads": 8,
                "positional_encoding": false,
                "inner_layer_dim": 128,
                "encoder_embedding_time_distributed": true,
                "last_layer_units": 128,
                "last_layer_activation": "relu",
                "dropout_rate": 0.01,

                "learning_rate": 0.0005
            }
        }
    }
}